{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db139b29-c059-4b4f-8ad5-bf77274a15cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, GenerationConfig\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334efd5c-e16d-44ce-94de-ad6c7eccc031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee6c63a-ce6d-4610-93d9-16a57f847c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparamters \n",
    "top_k = 50\n",
    "top_p = 0.9\n",
    "temp = 0.8\n",
    "min_new_tokens = 10\n",
    "max_new_tokens = 50\n",
    "do_sample=True\n",
    "num_beams=1\n",
    "\n",
    "dataset_name=\"PubMedQA\"\n",
    "model_name= \"EleutherAI/gpt-neo-1.3B\"\n",
    "batch_size=8\n",
    "max_input_length=2048\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "access_token = \"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\"\n",
    "cache_dir=\"/data/james/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9a5a77-0973-48ac-8290-2e573d2bc654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, metrics=None):\n",
    "        if not metrics:\n",
    "            metrics = [\"rouge\", \"sacre_bleu\", \"bertscore\", \"factkb\"]\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def evaluate(self, predictions, references, documents, metrics=[\"rouge\", \"bertscore\", \"factkb\", \"alignscore\"]):\n",
    "        result_dict = OrderedDict()\n",
    "        if \"rouge\" in metrics:\n",
    "            rouge_dict = self.calculate_rouge(predictions, references)\n",
    "            for k, v in rouge_dict.items():\n",
    "                result_dict[k] = v\n",
    "        if \"sacre_bleu\" in metrics:\n",
    "            sacre_bleu_dict = self.calculate_sacrebleu(predictions, references)\n",
    "            for k, v in sacre_bleu_dict.items():\n",
    "                result_dict[k] = v\n",
    "        if \"bertscore\" in metrics:\n",
    "            bertscore_dict = self.calculate_bertscore(predictions, references)\n",
    "            for k, v in bertscore_dict.items():\n",
    "                result_dict[k] = v\n",
    "        if \"factkb\" in metrics:\n",
    "            result_dict[\"factkb\"] = self.calculate_factkb(predictions, documents)\n",
    "            \n",
    "        if \"alignscore\" in metrics:\n",
    "            result_dict[\"alignscore\"] = self.calculate_alignscore(predictions, documents) \n",
    "\n",
    "        for k, v in result_dict.items():\n",
    "            print(f\"{k} -> {v*100:.2f}\")\n",
    "        return result_dict\n",
    "\n",
    "    def calculate_rouge(self, predictions, references):\n",
    "        from torchmetrics.functional.text.rouge import rouge_score\n",
    "        rouge_dict = rouge_score(preds=predictions, target=references)\n",
    "        return {k: v.item() for k, v in rouge_dict.items()}\n",
    "\n",
    "    def calculate_sacrebleu(self, predictions, references):\n",
    "        from torchmetrics.functional.text import sacre_bleu_score\n",
    "        score = sacre_bleu_score(preds=predictions, target=[[i] for i in references])\n",
    "        return {\"sacre_bleu\": score.item()}\n",
    "\n",
    "    def calculate_bertscore(self, predictions, references):\n",
    "        import evaluate\n",
    "        bertscore = evaluate.load(\"bertscore\")\n",
    "        bertscore_dict = bertscore.compute(predictions=predictions, references=references, model_type=\"roberta-large-mnli\")\n",
    "        res = {\"bertscore_precision\": np.mean(bertscore_dict[\"precision\"]), \"bertscore_recall\": np.mean(bertscore_dict[\"recall\"]), \"bertscore_f1\": np.mean(bertscore_dict[\"f1\"])}\n",
    "        return {k: v.item() for k, v in res.items()}\n",
    "    \n",
    "    def calculate_alignscore(self, predictions, documents):\n",
    "        from AlignScore.src.alignscore import AlignScore\n",
    "        ckpt_path = \"models/AlignScore-base.ckpt\"\n",
    "        align_scorer = AlignScore(model='roberta-base', batch_size=8, device=DEVICE, ckpt_path=ckpt_path, evaluation_mode='nli_sp')\n",
    "        alignscore_result = align_scorer.score(contexts=documents, claims=predictions)\n",
    "        #total_result['AlignScore'] = 100*np.mean(alignscore_result)\n",
    "        return np.mean(alignscore_result)\n",
    "\n",
    "    def calculate_factkb(self, predictions, documents):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", padding=\"max_length\", truncation=True, cache_dir=cache_dir)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"bunsenfeng/FactKB\", torch_dtype=torch.float16, cache_dir=cache_dir)\n",
    "        model = model.to(DEVICE)\n",
    "        res = []\n",
    "        for i in range(len(predictions)):\n",
    "            input_pretokenized = f\"{predictions[i]} {tokenizer.sep_token} {documents[i]}\"\n",
    "            tokenized_input = tokenizer(input_pretokenized, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                output = model(input_ids=tokenized_input.input_ids.to(DEVICE))\n",
    "            logits = torch.softmax(output.logits, dim=1)  # (bz, 2)\n",
    "            res.append(logits.squeeze()[-1].item())\n",
    "        return np.mean(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6f9c07-b5b5-461d-adb1-00580c2aa643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def xsum_pretokenize(dataset, tokenizer, max_input_length):\n",
    "    data = {\"context\": [], \"query\": [], \"summary\": []}\n",
    "    for i, row in tqdm(enumerate(dataset), desc=\"truncating documents...\"):\n",
    "        trunc_doc = tokenizer.batch_decode(tokenizer(row['document'], return_tensors=\"pt\", max_length=max_input_length,  truncation=True).input_ids, skip_special_tokens=True)[0]\n",
    "        data['context'].append(trunc_doc)\n",
    "        data['summary'].append(row['summary'])\n",
    "        data[\"query\"].append(\"Summarize the article in one sentence. Summary:\")\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "def cnn_pretokenize(dataset, tokenizer, max_input_length):\n",
    "    data = {\"context\": [], \"query\": [], \"summary\": []}\n",
    "    for i, row in tqdm(enumerate(dataset), desc=\"truncating documents...\"):\n",
    "        trunc_doc = tokenizer.batch_decode(tokenizer(row['article'], return_tensors=\"pt\", max_length=max_input_length,  truncation=True).input_ids, skip_special_tokens=True)[0]\n",
    "        data['context'].append(trunc_doc)\n",
    "        data['summary'].append(row['highlights'])\n",
    "        data['query'].append(\"Summarize the article in one sentence. Summary:\")\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "def pubmedqa_pretokenize(dataset, tokenizer, max_input_length):\n",
    "    data = {\"context\": [], \"query\": [], \"summary\": []}\n",
    "    for i, row in tqdm(enumerate(dataset), desc=\"truncating documents...\"):\n",
    "        context= ''.join(c for c in row['context']['contexts'])\n",
    "        trunc_doc = tokenizer.batch_decode(tokenizer(context, return_tensors=\"pt\", max_length=max_input_length, truncation=True).input_ids, skip_special_tokens=True)[0]\n",
    "        data['context'].append(trunc_doc)\n",
    "        data['summary'].append(row['long_answer'])\n",
    "        data['query'].append(f\"Question: {row['question']}. Answer:\")\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "def pretokenize(dataset_name, dataset, tokenizer, max_input_length):\n",
    "    if dataset_name == \"xsum\":\n",
    "        return xsum_pretokenize(dataset, tokenizer, max_input_length)\n",
    "    elif dataset_name == \"cnn\":\n",
    "        return cnn_pretokenize(dataset, tokenizer, max_input_length)\n",
    "    elif dataset_name == \"PubMedQA\":\n",
    "        return pubmedqa_pretokenize(dataset, tokenizer, max_input_length)\n",
    "    return None\n",
    "\n",
    "def template_input(row, dataset):\n",
    "    if dataset == \"xsum\" or dataset == \"cnn\":\n",
    "        return f\"Article: {row['context']}. {row['query']}\"\n",
    "    elif dataset == \"PubMedQA\":\n",
    "        return f\"Document: {row['context']}. {row['query']}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def template_empty_input(row, dataset):\n",
    "    if dataset == \"xsum\" or dataset == \"cnn\":\n",
    "        return f\"Article: . {row['query']}\"\n",
    "    elif dataset == \"PubMedQA\":\n",
    "        return f\"Document: . {row['query']}\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53db7de-5b48-46ee-b2a5-a421e0462638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          padding_side=\"left\",\n",
    "                                          use_fast=False,\n",
    "                                          token=access_token,\n",
    "                                          trust_remote_code=True,\n",
    "                                          cache_dir=cache_dir)\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"True\")\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id = tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d380e0c8-bdd3-4b8c-9bcf-29cd00f9b5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset_name == \"PubMedQA\":\n",
    "    raw_test_set = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\", cache_dir=cache_dir)['train']\n",
    "elif dataset_name == 'xsum':\n",
    "    raw_test_set = load_dataset(dataset_name, split=\"test[:1000]\")\n",
    "elif dataset_name == 'cnn':\n",
    "    raw_test_set = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=\"test[:1000]\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68f6806-7061-4085-887c-09371a45f127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "truncating documents...: 1000it [00:06, 152.01it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set = pretokenize(dataset_name, raw_test_set, tokenizer, max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02695206-4fe0-416f-b28c-24f5c57f1ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for Pure DP decoding \n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import bisect\n",
    "    \n",
    "def top_k_top_p_filtering(logits, top_k, top_p, filter_value=-float(\"Inf\")):\n",
    "    indicies_to_remove = 0\n",
    "    if top_k > 0:\n",
    "        #  Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    \n",
    "    if top_p < 1.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold (token with 0 are kept)\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "        # scatter sorted tensors to original indexing\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    \n",
    "    return logits, indices_to_remove\n",
    "    \n",
    "def renyiDiv(p, q, alpha=float('inf')):\n",
    "        if alpha == float('inf'):\n",
    "            RD = torch.log(torch.max(p/q))\n",
    "        elif alpha == 1:\n",
    "            RD = torch.sum(p*torch.log(p/q))\n",
    "        else:\n",
    "            RD = 1/(alpha-1) * torch.log(\n",
    "                torch.sum(((p/q)**(alpha))*q)\n",
    "            )\n",
    "        if torch.isnan(RD):\n",
    "            RD = torch.log(torch.max(p/q))\n",
    "        return RD\n",
    "    \n",
    "def renyi_priv_loss(p, q, alpha):\n",
    "    return max(renyiDiv(p, q, alpha=alpha), renyiDiv(q, p, alpha=alpha)).cpu().numpy()\n",
    "\n",
    "def calculate_memorization(p, q, idx):\n",
    "    return max(torch.log(p[idx]/q[idx]), torch.log(q[idx]/p[idx])).cpu().numpy()  \n",
    "\n",
    "def entropy(p):\n",
    "    return (-np.sum(p*np.log(p)))\n",
    "\n",
    "def lambda_solver_bisection(p, p_0, epsilon, alpha):\n",
    "    def f(lambd):\n",
    "        pred = lambd * p + (1-lambd) * p_0\n",
    "        #eps = np.max([np.max(np.log(pred/p_0)), np.max(np.log(p_0/pred))])\n",
    "        eps = max(renyiDiv(pred, p_0, alpha=alpha), renyiDiv(p_0, pred, alpha=alpha))\n",
    "        return (eps - epsilon)\n",
    "    if f(1) <= 0.0:\n",
    "        lambd = 1\n",
    "    else:\n",
    "        lambd = bisect(f, 0, 1, maxiter=20, disp=False)\n",
    "    return lambd\n",
    "\n",
    "def lambda_solver(p, p_0, epsilon):\n",
    "    a = (p_0 * (np.exp(epsilon/2) - 1)) / torch.abs(p - p_0)\n",
    "    val = torch.min(a)\n",
    "    return min(1, val)\n",
    "\n",
    "def mollify(p, p_0, epsilon, ids, alpha):\n",
    "    #lambd = lambda_solver(p[ids], p_0[ids], epsilon)\n",
    "    lambd = lambda_solver_bisection(p[ids].cpu(), p_0[ids].cpu(), epsilon, alpha)\n",
    "    return (lambd * p + (1-lambd) * p_0), lambd    \n",
    "\n",
    "def calc_partition_loss(proj_logit, proj_output, pub_output, alpha, temperature):\n",
    "    max_loss = 0\n",
    "    for i in range(proj_logit.shape[0]):\n",
    "        proj_logit_i = torch.cat([proj_logit[:i, :], proj_logit[i+1:, :]])\n",
    "        proj_output_i = F.softmax(proj_logit_i / temperature, dim=-1).mean(dim=0)\n",
    "        ids = torch.nonzero(proj_output)\n",
    "        eps = renyi_priv_loss(proj_output[ids], proj_output_i[ids], alpha)\n",
    "        max_loss = max(max_loss, eps)\n",
    "    return max_loss\n",
    "\n",
    "def calc_group_memorization(ensemble_outputs, idx):\n",
    "    return max([calculate_memorization(ensemble_outputs[0, :], ensemble_outputs[i, :], idx) for i in range(1, ensemble_outputs.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc4cab5-6d85-4bda-8639-b2079f259a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_calc_memorization(model,\n",
    "                   context_aware_input_ids,\n",
    "                   context_unaware_input_ids,\n",
    "                   response_input_ids,\n",
    "                   lambd,\n",
    "                   temperature,\n",
    "                   stop_token_ids,\n",
    "                   min_length,\n",
    "                   batch_size=None\n",
    "                  ):\n",
    "    mem_vals = []\n",
    "    N = context_aware_input_ids.shape[0]\n",
    "    for t in range(response_input_ids.shape[1]):\n",
    "        priv_context_aware_input_ids = torch.cat([context_aware_input_ids,\n",
    "                                      response_input_ids[:, :t].repeat(N, 1)],\n",
    "                                     dim=1)\n",
    "        pub_logit = model(torch.cat([context_unaware_input_ids,\n",
    "                                     response_input_ids[:, :t]],\n",
    "                                    dim=1)\n",
    "                         ).logits.squeeze()[-1, :].type(torch.float64)\n",
    "        if batch_size == None:\n",
    "            priv_logit = model(priv_context_aware_input_ids).logits[:, -1, :].type(torch.float64)\n",
    "        else:\n",
    "            priv_logit = torch.stack([model(priv_context_aware_input_ids[i:(i+1)*batch_size]).logits[:, -1, :].type(torch.float64)\n",
    "                     for i in range(0, N, batch_size)])\n",
    "        proj_logit = lambd * priv_logit + (1-lambd) * pub_logit.repeat(N, 1)\n",
    "        \n",
    "        if t < min_length:\n",
    "            pub_logit[stop_token_ids[0]] = -float(\"Inf\")\n",
    "            proj_logit[:, stop_token_ids[0]] = -float(\"Inf\")\n",
    "            \n",
    "        if pub_logit.shape[0] > len(tokenizer):\n",
    "            pub_logit[len(tokenizer):pub_logit.shape[0]] = -float(\"Inf\")\n",
    "            proj_logit[:, len(tokenizer):pub_logit.shape[0]] = -float(\"Inf\")\n",
    "        \n",
    "        pub_output = F.softmax(pub_logit / temperature, dim=-1)\n",
    "        priv_output = F.softmax(priv_logit / temperature, dim=-1)\n",
    "        proj_output = F.softmax(proj_logit / temperature, dim=-1)\n",
    "        \n",
    "        ids = torch.nonzero(pub_output)\n",
    "        mem_val = calc_group_memorization(proj_output[:, ids].squeeze(), response_input_ids[:, t])\n",
    "        mem_vals.append(mem_val[0])\n",
    "        \n",
    "    return mem_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfb0b43-28b3-4b55-89ef-e31a9c502360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def partition(data, tokenizer, partition_length, dataset_name):\n",
    "    document_ids = tokenizer(data['context']).input_ids\n",
    "    ensemble = []\n",
    "    for i in range(0, len(document_ids), partition_length):\n",
    "        idx = (i+partition_length)\n",
    "        #ensemble = torch.cat([ensemble, input_ids[-1:, idx:i]], dim=1)\n",
    "        row = {'context': tokenizer.decode(document_ids[i:idx], skip_special_tokens=True), 'query': data['query']}\n",
    "        ensemble.append(template_input(row, dataset_name))\n",
    "    return ensemble\n",
    "\n",
    "def group_partition(data, tokenizer, partition_length, dataset_name):\n",
    "    document_ids = tokenizer(data['context']).input_ids\n",
    "    groups = [template_input(data, dataset_name)]\n",
    "    for i in range(0, len(document_ids), partition_length):\n",
    "        idx = (i+partition_length)\n",
    "        group_i = document_ids[:i] + document_ids[idx:]\n",
    "        row = {'context': tokenizer.decode(group_i, skip_special_tokens=True), 'query': data['query']}\n",
    "        groups.append(template_input(row, dataset_name))\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23fde59f-b6a9-4439-bdfa-0c0601e14a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cmad_generation(model,\n",
    "                  context_aware_input_ids,\n",
    "                  context_unaware_input_ids,\n",
    "                  lambd,\n",
    "                  temperature,\n",
    "                  max_length,\n",
    "                  min_length,\n",
    "                  stop_token_ids,\n",
    "                  device,\n",
    "                 ):\n",
    "    response_input_ids = torch.LongTensor([[]]).to(device)\n",
    "    for i in range(max_length):\n",
    "        priv_context_aware_input_ids = torch.cat([context_aware_input_ids,\n",
    "                                      response_input_ids.repeat(context_aware_input_ids.shape[0], 1)],\n",
    "                                     dim=1)\n",
    "        pub_logit = model(torch.cat([context_unaware_input_ids,\n",
    "                                     response_input_ids],\n",
    "                                    dim=1)\n",
    "                         ).logits.squeeze()[-1, :].type(torch.float64)\n",
    "\n",
    "        priv_logit = model(priv_context_aware_input_ids).logits[:, -1, :].type(torch.float64)\n",
    "        proj_logit = lambd * priv_logit + (1-lambd) * pub_logit.repeat(priv_logit.shape[0], 1)\n",
    "        \n",
    "        if i < min_length:\n",
    "            pub_logit[stop_token_ids[0]] = -float(\"Inf\")\n",
    "            proj_logit[:, stop_token_ids[0]] = -float(\"Inf\")\n",
    "            \n",
    "        if pub_logit.shape[0] > len(tokenizer):\n",
    "            pub_logit[len(tokenizer):pub_logit.shape[0]] = -float(\"Inf\")\n",
    "            proj_logit[:, len(tokenizer):pub_logit.shape[0]] = -float(\"Inf\")\n",
    "            \n",
    "        pub_output = F.softmax(pub_logit / temperature, dim=-1)\n",
    "        #priv_output = F.softmax(priv_logit, dim=-1)[-1]\n",
    "        proj_output = F.softmax(proj_logit / temperature, dim=-1)\n",
    "\n",
    "        pred_idx = proj_output[0].multinomial(1).view(1, -1).long()\n",
    "        if pred_idx.cpu()[0].item() in stop_token_ids:\n",
    "            break\n",
    "\n",
    "        response_input_ids = torch.cat([response_input_ids, pred_idx], dim=1)\n",
    "        del pred_idx\n",
    "    return response_input_ids.cpu()[0], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b8aa8a-0b65-4182-ba87-d7c7ba3d0441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_experiment(test_set, model, tokenizer, lambd, temperature, dataset_name, min_length):\n",
    "    dp_predictions = []\n",
    "    stop_token_ids = [tokenizer.eos_token_id,\n",
    "                      tokenizer.pad_token_id,\n",
    "                     ]\n",
    "    doc_priv_loss = [] \n",
    "    for idx, data in tqdm(enumerate(test_set), total=len(test_set)):\n",
    "        context_unaware_tokenized_input = tokenizer(template_empty_input(data, dataset_name), return_tensors=\"pt\", padding=True)\n",
    "        context_aware_tokenized_input = tokenizer(template_input(data, dataset_name), return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            dp_output, doc_eps = cmad_generation(model,\n",
    "                                    context_aware_tokenized_input.input_ids.to(DEVICE),\n",
    "                                    context_unaware_tokenized_input.input_ids.to(DEVICE),\n",
    "                                    lambd=lambd,\n",
    "                                    temperature=temperature,\n",
    "                                    max_length=max_new_tokens,\n",
    "                                    min_length=min_length,\n",
    "                                    stop_token_ids=stop_token_ids,\n",
    "                                    device=DEVICE,\n",
    "                                    )\n",
    "        decode_dp_output = tokenizer.decode(dp_output, skip_special_tokens=True)\n",
    "        dp_predictions.append(decode_dp_output)\n",
    "        doc_priv_loss.append(doc_eps)\n",
    "    return dp_predictions, doc_priv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c430e6b-3217-4812-9184-e007c911433c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_name = \"results\"\n",
    "m_name = \"gpt-neo-1.3B\"\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295cf787-4c58-4b3c-84b1-778d8080ea15",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "truncating documents...: 1000it [00:07, 142.12it/s]\n",
      "  3%|█▎                                                  | 26/1000 [00:57<35:19,  2.18s/it]"
     ]
    }
   ],
   "source": [
    "os.makedirs(dir_name, exist_ok=True)\n",
    "lambds = [0.5, 1.0, 1.5]\n",
    "model_names = [\"EleutherAI/gpt-neo-1.3B\"]\n",
    "m_names = [\"gpt-neo-1.3B\"]#, \"Meta-Llama-3-8B\"]\n",
    "for model_name, m_name in zip(model_names, m_names):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          #padding_side=\"left\",\n",
    "                                          use_fast=False,\n",
    "                                          token=access_token,\n",
    "                                          trust_remote_code=True,\n",
    "                                          cache_dir=cache_dir)\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        print(\"True\")\n",
    "        tokenizer.pad_token, tokenizer.pad_token_id = tokenizer.eos_token, tokenizer.eos_token_id\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        token=access_token,\n",
    "        cache_dir=cache_dir,\n",
    "        #device_map=\"auto\"\n",
    "        ).to(DEVICE)\n",
    "    \n",
    "    test_set = pretokenize(dataset_name, raw_test_set, tokenizer, max_input_length)\n",
    "    \n",
    "    for lambd in lambds:\n",
    "        #file_name = f'{dataset_name}_{m_name}_{lambd}_context{max_input_length}.csv'\n",
    "        file_name = f'{dataset_name}_{m_name}_{lambd}.csv'\n",
    "        dp_predictions, dp_loss = decode_experiment(test_set, model, tokenizer, lambd=lambd, temperature=0.8, dataset_name=dataset_name, min_length=10)\n",
    "        df = pd.DataFrame({'generations': dp_predictions, 'privacy_loss': dp_loss})\n",
    "        df.to_csv(os.path.join(dir_name, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd69e2-a5f1-4aa4-81c2-c95fdd69e550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents, references = [], []\n",
    "for idx, data in tqdm(enumerate(test_set), total=len(test_set)):\n",
    "    documents.append(data['context'])\n",
    "    references.append(data['summary'])\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b75a7ada-e105-4d13-9cb5-d14ee76356f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambd=0.5\n",
    "file_name = f'{dataset_name}_{m_name}_{lambd}.csv'\n",
    "df = pd.read_csv(os.path.join(dir_name, file_name))\n",
    "doc_priv_loss = df['privacy_loss']\n",
    "predictions = df['generations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f37390a-c4c7-4eda-aace-e6c95972146f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        token=access_token,\n",
    "        cache_dir=cache_dir,\n",
    "        #device_map=\"auto\"\n",
    "        ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3a1c2db-714d-472e-abd1-8a466c7f168d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_priv_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3dd6c-11e3-4829-966c-4b43da6d9088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing module\n",
    "import logging\n",
    "\n",
    "partition_len = max_input_length\n",
    "temperature=0.8\n",
    "stop_token_ids = [tokenizer.eos_token_id,\n",
    "                      tokenizer.pad_token_id,\n",
    "                     ]\n",
    "query_set = test_set.select(range(1000))\n",
    "\n",
    "lambds = [0.5, 1.0, 1.5]\n",
    "mean_vals = []\n",
    "vals = []\n",
    "for lambd in lambds:\n",
    "    file_name = f'{dataset_name}_{m_name}_{lambd}.csv'\n",
    "    #file_name = f'{dataset_name}_{m_name}_{lambd}_context{max_input_length}.csv'\n",
    "    df = pd.read_csv(os.path.join(dir_name, file_name))\n",
    "    predictions = df['generations']\n",
    "    mem_vals = []\n",
    "    for data, response in tqdm(zip(query_set, predictions), total=len(query_set)):\n",
    "        context_unaware_tokenized_input = tokenizer(template_empty_input(data, dataset_name), return_tensors=\"pt\", padding=True)\n",
    "        ensemble = group_partition(data, tokenizer, partition_len, dataset_name=dataset_name)\n",
    "        context_aware_tokenized_input = tokenizer(ensemble, return_tensors=\"pt\", max_length=max_input_length+25, padding=True, truncation=True)\n",
    "        response_tokenized_input = tokenizer(response, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            cur_mem = post_calc_memorization(model,\n",
    "                                       context_aware_tokenized_input.input_ids.to(DEVICE),\n",
    "                                       context_unaware_tokenized_input.input_ids.to(DEVICE),\n",
    "                                       response_tokenized_input.input_ids.to(DEVICE)[:, 1:],\n",
    "                                       lambd,\n",
    "                                       temperature,\n",
    "                                       stop_token_ids,\n",
    "                                       min_new_tokens,\n",
    "                                       batch_size=None\n",
    "                                      )\n",
    "        vals.append(cur_mem)\n",
    "    #mean_vals.append(np.mean(mem_vals))\n",
    "    mem_vals = np.zeros([len(vals),len(max(vals,key = lambda x: len(x)))])\n",
    "    for i,j in enumerate(vals):\n",
    "        mem_vals[i, 0:len(j)] = j\n",
    "    print(np.mean(np.sum(mem_vals, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffbf5ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.82170758486512\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.sum(mem_vals, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6ded613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_vals = np.mean(mem_vals, axis=0)\n",
    "plt.plot(np.arange(0, len(mean_vals)), mean_vals)\n",
    "plt.xlabel(\"Generation Length $|\\mathbf{y}|$\")\n",
    "plt.ylabel(r'$\\mathbb{E}[f_{\\text{Mem}}(\\overline{p}_{\\theta})]$')\n",
    "plt.savefig(\"gen_len_analysis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51949960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46d1ad54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_Meta-Llama-3-8B_1.0.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f426ec09-c9a8-4db5-8ffc-91f0972ca151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/james/memorization_and_hallucination/venv/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)  # type: ignore[arg-type]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.7.7 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file models/AlignScore-base.ckpt`\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/james/memorization_and_hallucination/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:255: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['base_model.embeddings.position_ids']\n",
      "  rank_zero_warn(\n",
      "Evaluating: 100%|██████████████████████████████████████| 1000/1000 [01:45<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1_fmeasure -> 13.54\n",
      "rouge1_precision -> 12.29\n",
      "rouge1_recall -> 15.89\n",
      "rouge2_fmeasure -> 1.18\n",
      "rouge2_precision -> 1.05\n",
      "rouge2_recall -> 1.42\n",
      "rougeL_fmeasure -> 10.23\n",
      "rougeL_precision -> 9.24\n",
      "rougeL_recall -> 12.08\n",
      "rougeLsum_fmeasure -> 12.20\n",
      "rougeLsum_precision -> 11.06\n",
      "rougeLsum_recall -> 14.35\n",
      "bertscore_precision -> 68.63\n",
      "bertscore_recall -> 67.46\n",
      "bertscore_f1 -> 68.03\n",
      "factkb -> 71.28\n",
      "alignscore -> 24.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict = evaluator.evaluate(predictions, references, documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b596499e6b756ee3ee734d514920d364bec1c6a0ebf031bda292a137927d8dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
